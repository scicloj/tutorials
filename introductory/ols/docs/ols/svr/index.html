<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="https://stackpath.bootstrapcdn.com/bootswatch/4.5.0/sandstone/bootstrap.min.css" rel="stylesheet" type="text/css">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/solarized-light.min.css" rel="stylesheet" type="text/css">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/ag-grid/24.0.0/styles/ag-grid.min.css" rel="stylesheet" type="text/css">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/ag-grid/24.0.0/styles/ag-theme-balham.min.css" rel="stylesheet" type="text/css">
        <link href="https://unpkg.com/leaflet@1.6.0/dist/leaflet.css" rel="stylesheet" type="text/css">

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
        <!-- The loading of KaTeX is deferred to speed up page rendering -->
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    </head>
    <body>
        <p id="loading">Loading ...</p>
        <div id="app"></div>
    </body>
    <script id="state" type="text">"{:options {:reverse-notes? false, :header? false, :notes-in-cards? false, :initially-collapse? false, :auto-scroll? false, :port 1903, :custom-header [:div {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} \"(notespace)\" [:p \"Wed Jul 21 00:15:05 IDT 2021\"] nil [:hr]], :custom-footer [:div [:hr] [:hr]]}, :ids [\"130\" \"131\" \"132\" \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\" \"145\" \"146\" \"147\" \"148\" \"149\" \"150\" \"151\" \"152\" \"153\" \"154\" \"155\" \"156\" \"157\" \"158\" \"159\" \"160\" \"161\" \"162\" \"163\" \"164\" \"165\" \"166\" \"167\" \"168\" \"169\" \"170\" \"171\" \"172\" \"173\" \"174\" \"175\" \"176\" \"177\" \"178\" \"179\" \"180\" \"181\"], :id->content {\"180\" [:div [:p] [:div [:p/code {:code \"(svr-predict-scalar svrmodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"127.29358711932846\\n\"}]], \"158\" [:div [:p] nil nil [:p/markdown \"This is the training function.\"]], \"141\" [:div [:p] [:div [:p/code {:code \"(defn legacy-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn dfn/exp}\\n   :transformations [{:column :Used_ZTW :assoc-fn #(dfn/log (% :Used_ZTW))}]\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}]] nil nil], \"139\" [:div [:p] [:div [:p/code {:code \"(ds/head qm)\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"resources/bonds.csv [5 6]:\\n\\n|  :Bond |     :Sector | :Country | :Used_Duration | :Used_Rating_Score | :Used_ZTW |\\n|--------|-------------|----------|----------------|--------------------|-----------|\\n| Bond-0 |    Cbafhzre |       BH |           4.65 |               15.0 |     688.6 |\\n| Bond-1 | Dvirefvsvrq |       BH |           4.57 |                7.0 |     188.8 |\\n| Bond-2 | Dvirefvsvrq |       BH |           3.35 |                9.0 |     243.9 |\\n| Bond-3 | Dvirefvsvrq |       BH |           5.45 |                9.0 |     319.0 |\\n| Bond-4 |   Fvanapvny |       BH |           2.38 |                6.0 |     125.4 |\\n\\n\"}]], \"157\" [:div [:p] [:div [:p/code {:code \"(defn fit-RBF-SVR [x y sigma eps C]\\n  \\\"This is the SVR fit function, returning a smile.base.svm.KernelMachine which we can use to predict.\\n  x id a double double array, y is a double array, the rest are scalars.\\n  tol = 0.01 is irrelevant for the RBF (= Gaussian) kernel.\\n  sigma tunes the Kernel. The Python sklearn default is gamma = 'scale' where gamma = 1 / (2 * sigma^2)\\n  'scale' means gamma = 1 / (n_features * x.var()) hence sigma = sqrt(0.5 * n_features * x.var()) where x is flattened\\\"\\n  (.fit (SVR. (GaussianKernel. sigma) eps C 0.01) x y))\", :bg-class \"bg-light\"}]] nil nil], \"175\" [:div [:p] nil nil [:p/markdown \"It's now easy to look at the predictions for any one bond in the dataset.\"]], \"155\" [:div [:p] [:div [:p/code {:code \"(defn ols-full-training\\n  [data]\\n  (let [ols (OLS/fit (:ols-formula data) (:dataframe data))]\\n    (merge data\\n           {:ols ols\\n            :predictions ((get-in data [:y :predict-fn]) (vec (.predict ^LinearModel ols ^DataFrame (:dataframe data))))\\n            :rsq (.RSquared ^LinearModel ols)})))\", :bg-class \"bg-light\"}]] nil nil], \"135\" [:div [:p] [:div [:p/code {:code \"(comment\\n  ;; we'll be calling some Java methods\\n  ;; commenting this out, since it fails as a notespace note\\n  ;; (Can't set!: *warn-on-reflection* from non-binding thread)\\n  (set! *warn-on-reflection* true))\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"nil\\n\"}]], \"169\" [:div [:p] [:div [:p/code {:code \"(def legacymodel (get-legacy-model-output qm))\", :bg-class \"bg-light\"}]] nil nil], \"179\" [:div [:p] [:div [:p/code {:code \"(ols-predict-scalar newmodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"103.1329755725272\\n\"}]], \"156\" [:div [:p] nil nil [:p/markdown \"Training the support vector regression model is slightly more tricky and will be done in two steps. The first function fits the model, returning a Kernel which we can then use to predict. Note smile uses `sigma` for the RBF Kernel whereas `scikit-learn` uses `gamma`, but they're equivalent.\"]], \"159\" [:div [:p] [:div [:p/code {:code \"(defn svr-full-training [data eps C]\\n  ;todo find out why I'm still getting a Reflection warning: call to method predict on smile.base.svm.KernelMachine can't be resolved (no such method)\\n  (let [kernel-machine (fit-RBF-SVR (:features-array data) (:y-array data) (:sigma data) eps C)\\n        raw-predictions (.predict ^KernelMachine kernel-machine (:features-array data))\\n        rss (RSS/of (:y-array data) raw-predictions)]\\n    (merge data\\n           {:kernel-machine kernel-machine\\n            :predictions ((get-in data [:y :predict-fn]) (vec raw-predictions))\\n            :rsq (- 1 (/ rss (dfn/distance-squared (:y-array data) (repeat 0.))))})))\", :bg-class \"bg-light\"}]] nil nil], \"162\" [:div [:p] [:div [:p/code {:code \"(defn ols-predict-scalar [data xmap]\\n  (letfn [(normalizer [id log?] (let [{m :mean s :standard-deviation} (get-in data [:std-scale :scaler id])]\\n                                  (/ (- (if log? (Math/log (xmap id)) (xmap id)) m) s)))]\\n    ((get-in data [:y :predict-fn])\\n     (.predict\\n       ^LinearModel (:ols data)\\n       (double-array\\n         (into [1.0] (for [c (:features-cols data)]          ;into [1.0] is the intercept. It's not obvious!!!\\n                       (condp = c\\n                         :Used_Duration (normalizer :Used_Duration (some #{:Used_Duration} (map :column (:transformations data))))\\n                         :Used_Rating_Score (normalizer :Used_Rating_Score false)\\n                         (keyword (str \\\"Country-\\\" (xmap :Country))) 1.0\\n                         (keyword (str \\\"Sector-\\\" (xmap :Sector))) 1.0\\n                         0.0))))))))\", :bg-class \"bg-light\"}]] nil nil], \"167\" [:div [:p] [:div [:p/code {:code \"(defn get-new-model-output\\n  [dataset]\\n  (-> dataset\\n      (new-model-definition)\\n      (prepare-data :ols)\\n      (ols-full-training)))\", :bg-class \"bg-light\"}]] nil nil], \"172\" [:div [:p] nil nil [:p/markdown \"Let's add columns with all predictions to the original dataset.\"]], \"176\" [:div [:p] [:div [:p/code {:code \"(ds/filter-column res :Bond \\\"Bond-42\\\")\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"resources/bonds.csv [1 9]:\\n\\n|   :Bond |     :Sector | :Country | :Used_Duration | :Used_Rating_Score | :Used_ZTW | :legacy |  :new |  :svr |\\n|---------|-------------|----------|----------------|--------------------|-----------|---------|-------|-------|\\n| Bond-42 | Ovy_naq_Gnf |       BH |           1.16 |                6.0 |      75.2 |   118.0 | 103.1 | 127.3 |\\n\\n\"}]], \"145\" [:div [:p] nil nil [:p/markdown \"We define a function that can create new columns into a dataset either from another column or from a row-by-row operation. We also define a reducer so we can apply several transformations at once.\"]], \"152\" [:div [:p] [:div [:p/code {:code \"(defn prepare-data\\n  \\\"model-type is :ols or :svr\\\"\\n  [model-definition model-type]\\n  (let [transformed (build-many-columns (:dataset model-definition) (:transformations model-definition))\\n        scaler (dsm/fit-std-scale (ds/select-columns transformed (get-in model-definition [:std-scale :columns])))\\n        clean-data (-> transformed\\n                       (one-hot-reducer (get-in model-definition [:one-hot :columns]) (get-in model-definition [:one-hot :removals]))\\n                       (dsm/transform-std-scale scaler))\\n        features-ds (ds/remove-columns clean-data [(:id-name model-definition) (get-in model-definition [:y :column])])]\\n    (assoc model-definition\\n      :std-scale      (assoc (:std-scale model-definition) :scaler scaler)\\n      :features-cols  (ds/column-names features-ds) ;we need to know the order to predict later\\n      :ols-formula    (if (= :ols model-type) (Formula/lhs (name (get-in model-definition [:y :column])))) ; need a name here, keyword will fail\\n      :dataframe      (if (= :ols model-type) (ds-smile/dataset->dataframe (ds/remove-column clean-data (:id-name model-definition))))\\n      :sigma          (if (= :svr model-type) (Math/sqrt (* 0.5 (ds/column-count features-ds) (dfn/variance (vec (flatten (ds/value-reader features-ds)))))))\\n      :features-array (if (= :svr model-type) (.toArray (ds-smile/dataset->dataframe features-ds)))\\n      :y-array        (if (= :svr model-type) (.array (ds-smile/column->smile-column (clean-data (get-in model-definition [:y :column]))))))))\", :bg-class \"bg-light\"}]] nil nil], \"181\" [:div [:p] nil nil [:p/markdown \"## END\"]], \"173\" [:div [:p] [:div [:p/code {:code \"(def res (assoc qm :legacy (:predictions legacymodel) :new (:predictions newmodel) :svr (:predictions svrmodel)))\", :bg-class \"bg-light\"}]] nil nil], \"148\" [:div [:p] nil nil [:p/markdown \"We define a one-hot reducer than can remove columns - this can be important for OLS models with small amount of features to avoid collinearity\"]], \"137\" [:div [:p] nil nil [:p/markdown \"The source data columns are `[:Bond :Used_Duration :Used_Rating_Score :Country :Sector]`. The target variable is called `:Used_ZTW` (z-spread to worst). The three models we run are:\\n* legacy: `log(Used_ZTW) = a.Used_Duration + b.Used_Rating_Score + categorical variables`\\n* new: `log(Used_ZTW) = a.log(Used_Duration) + b.Used_Rating_Score + categorical variables`\\n* svr: `Used_ZTW = SVR(Used_Duration, Used_Rating_Score, Country, Sector)`\"]], \"140\" [:div [:p] nil nil [:p/markdown \"For each model, we define which columns are categorical and need one-hot treatment, which need standard scaling, and which transformations will be applied to the data.\"]], \"136\" [:div [:p] nil nil [:p/markdown \"## Model definitions\"]], \"166\" [:div [:p] [:div [:p/code {:code \"(defn get-legacy-model-output\\n  [dataset]\\n  (-> dataset\\n      (legacy-model-definition)\\n      (prepare-data :ols)\\n      (ols-full-training)))\", :bg-class \"bg-light\"}]] nil nil], \"168\" [:div [:p] [:div [:p/code {:code \"(defn get-svr-model-output\\n  [dataset]\\n  (-> dataset\\n      (svr-model-definition)\\n      (prepare-data :svr)\\n      (svr-full-training 0.05 1)))\", :bg-class \"bg-light\"}]] nil nil], \"154\" [:div [:p] nil nil [:p/markdown \"Training an OLS model is easy - we add the predictions and the R2.\"]], \"174\" [:div [:p] [:div [:p/code {:code \"(ds/head res)\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"resources/bonds.csv [5 9]:\\n\\n|  :Bond |     :Sector | :Country | :Used_Duration | :Used_Rating_Score | :Used_ZTW | :legacy |  :new |  :svr |\\n|--------|-------------|----------|----------------|--------------------|-----------|---------|-------|-------|\\n| Bond-0 |    Cbafhzre |       BH |           4.65 |               15.0 |     688.6 |   965.8 |  1035 | 458.3 |\\n| Bond-1 | Dvirefvsvrq |       BH |           4.57 |                7.0 |     188.8 |   178.0 | 192.3 | 158.5 |\\n| Bond-2 | Dvirefvsvrq |       BH |           3.35 |                9.0 |     243.9 |   258.4 | 272.4 | 222.4 |\\n| Bond-3 | Dvirefvsvrq |       BH |           5.45 |                9.0 |     319.0 |   289.1 | 312.6 | 232.0 |\\n| Bond-4 |   Fvanapvny |       BH |           2.38 |                6.0 |     125.4 |   121.2 | 121.0 | 91.22 |\\n\\n\"}]], \"171\" [:div [:p] [:div [:p/code {:code \"(def svrmodel (get-svr-model-output qm))\", :bg-class \"bg-light\"}]] nil nil], \"130\" [:div [:p] nil nil nil], \"149\" [:div [:p] [:div [:p/code {:code \"(defn one-hot-reducer\\n  [source-dataset cols removals]\\n  (ds/remove-columns\\n    (reduce (fn [dataset col] (categorical/transform-one-hot dataset (categorical/fit-one-hot dataset col))) source-dataset cols)\\n    removals))\", :bg-class \"bg-light\"}]] nil nil], \"144\" [:div [:p] nil nil [:p/markdown \"## Preparing the data for smile processing\"]], \"134\" [:div [:p] nil nil [:p/markdown \"Note we are using smile Java interop. There's a \\\"native\\\" Clojure implementation but more doc for the Java version, hence using that one.\\n\"]], \"146\" [:div [:p] [:div [:p/code {:code \"(defn build-column\\n  [dataset line]\\n  (if (contains? line :assoc-fn)\\n    (assoc dataset (:column line) ((:assoc-fn line) dataset))\\n    (ds/column-map dataset (:column line) (:map-fn line) nil (:arg-cols line))))\", :bg-class \"bg-light\"}]] nil nil], \"177\" [:div [:p] nil nil [:p/markdown \"We can also try and predict the spread for any bond.\"]], \"165\" [:div [:p] nil nil [:p/markdown \"Piping is very natural with all functions taking dataset first.\"]], \"153\" [:div [:p] nil nil [:p/markdown \"## Preparing the data for smile processing\"]], \"142\" [:div [:p] [:div [:p/code {:code \"(defn new-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn dfn/exp}\\n   :transformations [{:column :Used_ZTW          :assoc-fn #(dfn/log (% :Used_ZTW))}\\n                     {:column :Used_Duration     :assoc-fn #(dfn/log (% :Used_Duration))}]\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}]] nil nil], \"138\" [:div [:p] [:div [:p/code {:code \"(def qm (ds/->dataset \\\"resources/bonds.csv\\\" {:key-fn keyword}))\", :bg-class \"bg-light\"}]] nil nil], \"133\" [:div [:p] nil nil [:p/markdown \"We take an anonymized dataset of bonds across countries and sectors, with their durations, ratings and spreads. We are trying to infer the spread from the other four factors. We will use two OLS models and one support vector regression model. Note that rating and duration are continuous variables, whereas country and sector are categorical variables.\"]], \"147\" [:div [:p] [:div [:p/code {:code \"(defn build-many-columns [dataset features]\\n  (reduce build-column dataset features))\", :bg-class \"bg-light\"}]] nil nil], \"151\" [:div [:p] nil nil [:p/markdown \"smile needs to receive double arrays and double double arrays as inputs. We also need to calculate `sigma` for the support vector regression. We will match the default in `scikit-learn` (more on that in the svr fit function). Finally, it is very important to keep a memory of the order of the features so we can use it to predict scalars later.\"]], \"143\" [:div [:p] [:div [:p/code {:code \"(defn svr-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn identity}\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}]] nil nil], \"178\" [:div [:p] [:div [:p/code {:code \"(ols-predict-scalar legacymodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}]] nil [:p/code {:code \"118.01535809799988\\n\"}]], \"170\" [:div [:p] [:div [:p/code {:code \"(def newmodel (get-new-model-output qm))\", :bg-class \"bg-light\"}]] nil nil], \"131\" [:div [:p] nil nil [:p/markdown \"# Multiple factor OLS and Support Vector regression with tech.ml.dataset and smile\"]], \"161\" [:div [:p] nil nil [:p/markdown \"The order of the data needs to match the order of the training data and *we need the intercept first, set at 1.0*. Note there's an ugly hack here in the ols predictor - normalizer is set to use log for the new model.\"]], \"164\" [:div [:p] nil nil [:p/markdown \"## Putting it all together\"]], \"163\" [:div [:p] [:div [:p/code {:code \"(defn svr-predict-scalar [data xmap]\\n  ;todo still getting a Reflection warning: call to method predict on smile.base.svm.KernelMachine can't be resolved (no such method)\\n  (letfn [(normalizer [id] (let [{m :mean s :standard-deviation} (get-in data [:std-scale :scaler id])]\\n                             (/ (- (xmap id) m) s)))]\\n    ((get-in data [:y :predict-fn])\\n     (.predict\\n       ^KernelMachine (:kernel-machine data)\\n       (double-array\\n         (into [] (for [c (:features-cols data)]\\n                    (condp = c\\n                      :Used_Duration (normalizer :Used_Duration)\\n                      :Used_Rating_Score (normalizer :Used_Rating_Score)\\n                      (keyword (str \\\"Country-\\\" (xmap :Country))) 1.0\\n                      (keyword (str \\\"Sector-\\\" (xmap :Sector))) 1.0\\n                      0.0))))))))\", :bg-class \"bg-light\"}]] nil nil], \"160\" [:div [:p] nil nil [:p/markdown \"## Scalar predictor functions\"]], \"150\" [:div [:p] nil nil [:p/markdown \"We now are ready to prepare the data. There are several steps here:\\n* transform the data\\n* scale columns and save the scaling function so it can be reused later when predicting\\n* apply one-hot transformation to categorical variables\\n* get the data into a shape that's acceptable for smile.\"]], \"132\" [:div [:p] nil nil [:p/markdown \"The purpose of this notebook is to show a basic machine learning pipeline with tech.ml.dataset.\"]]}}"</script>
    <script src="gorilla-notes/js/compiled/main.js"></script>
</html>
