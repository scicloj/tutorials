<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="https://stackpath.bootstrapcdn.com/bootswatch/4.5.0/sandstone/bootstrap.min.css" rel="stylesheet" type="text/css">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/solarized-light.min.css" rel="stylesheet" type="text/css">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/ag-grid/24.0.0/styles/ag-grid.min.css" rel="stylesheet" type="text/css">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/ag-grid/24.0.0/styles/ag-theme-balham.min.css" rel="stylesheet" type="text/css">
        <link href="https://unpkg.com/leaflet@1.6.0/dist/leaflet.css" rel="stylesheet" type="text/css">
    </head>
    <body>
        <p id="loading">Loading ...</p>
        <div id="app"></div>
    </body>
    <script src="https://cdn.jsdelivr.net/gh/scicloj/gorilla-notes@master/dist/0.5.0-SNAPSHOT-5/main.js"></script>
    <script>
     shadow.loader.load("main");
     gorilla_notes.main.main_BANG_(false, "{:options {:reverse-notes? false, :header? false, :notes-in-cards? false, :custom-header [:div {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} \"(notespace)\" [:p \"Fri Dec 18 00:28:57 IST 2020\"] nil nil [:hr]], :custom-footer [:div [:hr]]}, :ids [\"158\" \"159\" \"160\" \"161\" \"162\" \"163\" \"164\" \"165\" \"166\" \"167\" \"168\" \"169\" \"170\" \"171\" \"172\" \"173\" \"174\" \"175\" \"176\" \"177\" \"178\" \"179\" \"180\" \"181\" \"182\" \"183\" \"184\" \"185\" \"186\" \"187\" \"188\" \"189\" \"190\" \"191\" \"192\" \"193\" \"194\" \"195\" \"196\" \"197\" \"198\" \"199\" \"200\" \"201\" \"202\" \"203\" \"204\" \"205\" \"206\" \"207\" \"208\" \"209\"], :id->content {\"191\" [:div [:p/code {:code \"(defn svr-predict-scalar [data xmap]\\n  ;todo still getting a Reflection warning: call to method predict on smile.base.svm.KernelMachine can't be resolved (no such method)\\n  (letfn [(normalizer [id] (let [{m :mean s :standard-deviation} (get-in data [:std-scale :scaler id])]\\n                             (/ (- (xmap id) m) s)))]\\n    ((get-in data [:y :predict-fn])\\n     (.predict\\n       ^KernelMachine (:kernel-machine data)\\n       (double-array\\n         (into [] (for [c (:features-cols data)]\\n                    (condp = c\\n                      :Used_Duration (normalizer :Used_Duration)\\n                      :Used_Rating_Score (normalizer :Used_Rating_Score)\\n                      (keyword (str \\\"Country-\\\" (xmap :Country))) 1.0\\n                      (keyword (str \\\"Sector-\\\" (xmap :Sector))) 1.0\\n                      0.0))))))))\", :bg-class \"bg-light\"}] [:div nil]], \"180\" [:div [:p/code {:code \"(defn prepare-data\\n  \\\"model-type is :ols or :svr\\\"\\n  [model-definition model-type]\\n  (let [transformed (build-many-columns (:dataset model-definition) (:transformations model-definition))\\n        scaler (dsm/fit-std-scale (ds/select-columns transformed (get-in model-definition [:std-scale :columns])))\\n        clean-data (-> transformed\\n                       (one-hot-reducer (get-in model-definition [:one-hot :columns]) (get-in model-definition [:one-hot :removals]))\\n                       (dsm/transform-std-scale scaler))\\n        features-ds (ds/remove-columns clean-data [(:id-name model-definition) (get-in model-definition [:y :column])])]\\n    (assoc model-definition\\n      :std-scale      (assoc (:std-scale model-definition) :scaler scaler)\\n      :features-cols  (ds/column-names features-ds) ;we need to know the order to predict later\\n      :ols-formula    (if (= :ols model-type) (Formula/lhs (name (get-in model-definition [:y :column])))) ; need a name here, keyword will fail\\n      :dataframe      (if (= :ols model-type) (ds-smile/dataset->dataframe (ds/remove-column clean-data (:id-name model-definition))))\\n      :sigma          (if (= :svr model-type) (Math/sqrt (* 0.5 (ds/column-count features-ds) (dfn/variance (vec (flatten (ds/value-reader features-ds)))))))\\n      :features-array (if (= :svr model-type) (.toArray (ds-smile/dataset->dataframe features-ds)))\\n      :y-array        (if (= :svr model-type) (.array (ds-smile/column->smile-column (clean-data (get-in model-definition [:y :column]))))))))\", :bg-class \"bg-light\"}] [:div nil]], \"108\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"188\" [:div nil [:div [:p/markdown \"## Scalar predictor functions\"]]], \"158\" [:div nil [:div nil]], \"201\" [:div [:p/code {:code \"(def res (assoc qm :legacy (:predictions legacymodel) :new (:predictions newmodel) :svr (:predictions svrmodel)))\", :bg-class \"bg-light\"}] [:div nil]], \"141\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"139\" [:div [:p/code {:code \"(defn svr-predict-scalar [data xmap]\\n  ;todo still getting a Reflection warning: call to method predict on smile.base.svm.KernelMachine can't be resolved (no such method)\\n  (letfn [(normalizer [id] (let [{m :mean s :standard-deviation} (get-in data [:std-scale :scaler id])]\\n                             (/ (- (xmap id) m) s)))]\\n    ((get-in data [:y :predict-fn])\\n     (.predict\\n       ^KernelMachine (:kernel-machine data)\\n       (double-array\\n         (into [] (for [c (:features-cols data)]\\n                    (condp = c\\n                      :Used_Duration (normalizer :Used_Duration)\\n                      :Used_Rating_Score (normalizer :Used_Rating_Score)\\n                      (keyword (str \\\"Country-\\\" (xmap :Country))) 1.0\\n                      (keyword (str \\\"Sector-\\\" (xmap :Sector))) 1.0\\n                      0.0))))))))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"157\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"185\" [:div [:p/code {:code \"(defn fit-RBF-SVR [x y sigma eps C]\\n  \\\"This is the SVR fit function, returning a smile.base.svm.KernelMachine which we can use to predict.\\n  x id a double double array, y is a double array, the rest are scalars.\\n  tol = 0.01 is irrelevant for the RBF (= Gaussian) kernel.\\n  sigma tunes the Kernel. The Python sklearn default is gamma = 'scale' where gamma = 1 / (2 * sigma^2)\\n  'scale' means gamma = 1 / (n_features * x.var()) hence sigma = sqrt(0.5 * n_features * x.var()) where x is flattened\\\"\\n  (.fit (SVR. (GaussianKernel. sigma) eps C 0.01) x y))\", :bg-class \"bg-light\"}] [:div nil]], \"175\" [:div [:p/code {:code \"(defn build-many-columns [dataset features]\\n  (reduce build-column dataset features))\", :bg-class \"bg-light\"}] [:div nil]], \"155\" [:div [:p/code {:code \"(ols-predict-scalar newmodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"202\" [:div [:p/code {:code \"(ds/head res)\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"resources/bonds.csv [5 9]:\\n\\n|  :Bond |     :Sector | :Country | :Used_Duration | :Used_Rating_Score | :Used_ZTW | :legacy |  :new |  :svr |\\n|--------|-------------|----------|----------------|--------------------|-----------|---------|-------|-------|\\n| Bond-0 |    Cbafhzre |       BH |           4.65 |               15.0 |     688.6 |   965.8 |  1035 | 458.3 |\\n| Bond-1 | Dvirefvsvrq |       BH |           4.57 |                7.0 |     188.8 |   178.0 | 192.3 | 158.5 |\\n| Bond-2 | Dvirefvsvrq |       BH |           3.35 |                9.0 |     243.9 |   258.4 | 272.4 | 222.4 |\\n| Bond-3 | Dvirefvsvrq |       BH |           5.45 |                9.0 |     319.0 |   289.1 | 312.6 | 232.0 |\\n| Bond-4 |   Fvanapvny |       BH |           2.38 |                6.0 |     125.4 |   121.2 | 121.0 | 91.22 |\\n\\n\"}]]], \"195\" [:div [:p/code {:code \"(defn get-new-model-output\\n  [dataset]\\n  (-> dataset\\n      (new-model-definition)\\n      (prepare-data :ols)\\n      (ols-full-training)))\", :bg-class \"bg-light\"}] [:div nil]], \"118\" [:div [:p/code {:code \"(defn new-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn dfn/exp}\\n   :transformations [{:column :Used_ZTW          :assoc-fn #(dfn/log (% :Used_ZTW))}\\n                     {:column :Used_Duration     :assoc-fn #(dfn/log (% :Used_Duration))}]\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"193\" [:div nil [:div [:p/markdown \"Piping is very natural with all functions taking dataset first.\"]]], \"196\" [:div [:p/code {:code \"(defn get-svr-model-output\\n  [dataset]\\n  (-> dataset\\n      (svr-model-definition)\\n      (prepare-data :svr)\\n      (svr-full-training 0.05 1)))\", :bg-class \"bg-light\"}] [:div nil]], \"207\" [:div [:p/code {:code \"(ols-predict-scalar newmodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"103.1329755725272\\n\"}]]], \"135\" [:div [:p/code {:code \"(defn svr-full-training [data eps C]\\n  ;todo find out why I'm still getting a Reflection warning: call to method predict on smile.base.svm.KernelMachine can't be resolved (no such method)\\n  (let [kernel-machine (fit-RBF-SVR (:features-array data) (:y-array data) (:sigma data) eps C)\\n        raw-predictions (.predict ^KernelMachine kernel-machine (:features-array data))\\n        rss (RSS/of (:y-array data) raw-predictions)]\\n    (merge data\\n           {:kernel-machine kernel-machine\\n            :predictions ((get-in data [:y :predict-fn]) (vec raw-predictions))\\n            :rsq (- 1 (/ rss (dfn/distance-squared (:y-array data) (repeat 0.))))})))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"123\" [:div [:p/code {:code \"(defn build-many-columns [dataset features]\\n  (reduce build-column dataset features))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"116\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"169\" [:div [:p/code {:code \"(defn legacy-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn dfn/exp}\\n   :transformations [{:column :Used_ZTW :assoc-fn #(dfn/log (% :Used_ZTW))}]\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}] [:div nil]], \"179\" [:div nil [:div [:p/markdown \"smile needs to receive double arrays and double double arrays as inputs. We also need to calculate `sigma` for the support vector regression. We will match the default in `scikit-learn` (more on that in the svr fit function). Finally, it is very important to keep a memory of the order of the features so we can use it to predict scalars later.\"]]], \"156\" [:div [:p/code {:code \"(svr-predict-scalar svrmodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"159\" [:div nil [:div [:p/markdown \"# Multiple factor OLS and Support Vector regression with tech.ml.dataset and smile\"]]], \"162\" [:div nil [:div [:p/markdown \"Note we are using smile Java interop. There's a \\\"native\\\" Clojure implementation but more doc for the Java version, hence using that one.\\n\"]]], \"192\" [:div nil [:div [:p/markdown \"## Putting it all together\"]]], \"113\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"167\" [:div [:p/code {:code \"(ds/head qm)\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"resources/bonds.csv [5 6]:\\n\\n|  :Bond |     :Sector | :Country | :Used_Duration | :Used_Rating_Score | :Used_ZTW |\\n|--------|-------------|----------|----------------|--------------------|-----------|\\n| Bond-0 |    Cbafhzre |       BH |           4.65 |               15.0 |     688.6 |\\n| Bond-1 | Dvirefvsvrq |       BH |           4.57 |                7.0 |     188.8 |\\n| Bond-2 | Dvirefvsvrq |       BH |           3.35 |                9.0 |     243.9 |\\n| Bond-3 | Dvirefvsvrq |       BH |           5.45 |                9.0 |     319.0 |\\n| Bond-4 |   Fvanapvny |       BH |           2.38 |                6.0 |     125.4 |\\n\\n\"}]]], \"197\" [:div [:p/code {:code \"(def legacymodel (get-legacy-model-output qm))\", :bg-class \"bg-light\"}] [:div nil]], \"107\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"115\" [:div [:p/code {:code \"(ds/head qm)\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"111\" [:div [:p/code {:code \"(comment\\n  ;; we'll be calling some Java methods\\n  ;; commenting this out, since it fails as a notespace note\\n  ;; (Can't set!: *warn-on-reflection* from non-binding thread)\\n  (set! *warn-on-reflection* true))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"203\" [:div nil [:div [:p/markdown \"It's now easy to look at the predictions for any one bond in the dataset.\"]]], \"172\" [:div nil [:div [:p/markdown \"## Preparing the data for smile processing\"]]], \"176\" [:div nil [:div [:p/markdown \"We define a one-hot reducer than can remove columns - this can be important for OLS models with small amount of features to avoid collinearity\"]]], \"119\" [:div [:p/code {:code \"(defn svr-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn identity}\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"145\" [:div [:p/code {:code \"(def legacymodel (get-legacy-model-output qm))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"128\" [:div [:p/code {:code \"(defn prepare-data\\n  \\\"model-type is :ols or :svr\\\"\\n  [model-definition model-type]\\n  (let [transformed (build-many-columns (:dataset model-definition) (:transformations model-definition))\\n        scaler (dsm/fit-std-scale (ds/select-columns transformed (get-in model-definition [:std-scale :columns])))\\n        clean-data (-> transformed\\n                       (one-hot-reducer (get-in model-definition [:one-hot :columns]) (get-in model-definition [:one-hot :removals]))\\n                       (dsm/transform-std-scale scaler))\\n        features-ds (ds/remove-columns clean-data [(:id-name model-definition) (get-in model-definition [:y :column])])]\\n    (assoc model-definition\\n      :std-scale      (assoc (:std-scale model-definition) :scaler scaler)\\n      :features-cols  (ds/column-names features-ds) ;we need to know the order to predict later\\n      :ols-formula    (if (= :ols model-type) (Formula/lhs (name (get-in model-definition [:y :column])))) ; need a name here, keyword will fail\\n      :dataframe      (if (= :ols model-type) (ds-smile/dataset->dataframe (ds/remove-column clean-data (:id-name model-definition))))\\n      :sigma          (if (= :svr model-type) (Math/sqrt (* 0.5 (ds/column-count features-ds) (dfn/variance (vec (flatten (ds/value-reader features-ds)))))))\\n      :features-array (if (= :svr model-type) (.toArray (ds-smile/dataset->dataframe features-ds)))\\n      :y-array        (if (= :svr model-type) (.array (ds-smile/column->smile-column (clean-data (get-in model-definition [:y :column]))))))))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"199\" [:div [:p/code {:code \"(def svrmodel (get-svr-model-output qm))\", :bg-class \"bg-light\"}] [:div nil]], \"186\" [:div nil [:div [:p/markdown \"This is the training function.\"]]], \"152\" [:div [:p/code {:code \"(ds/filter-column res :Bond \\\"Bond-42\\\")\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"181\" [:div nil [:div [:p/markdown \"## Preparing the data for smile processing\"]]], \"184\" [:div nil [:div [:p/markdown \"Training the support vector regression model is slightly more tricky and will be done in two steps. The first function fits the model, returning a Kernel which we can then use to predict. Note smile uses `sigma` for the RBF Kernel whereas `scikit-learn` uses `gamma`, but they're equivalent.\"]]], \"106\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"173\" [:div nil [:div [:p/markdown \"We define a function that can create new columns into a dataset either from another column or from a row-by-row operation. We also define a reducer so we can apply several transformations at once.\"]]], \"190\" [:div [:p/code {:code \"(defn ols-predict-scalar [data xmap]\\n  (letfn [(normalizer [id log?] (let [{m :mean s :standard-deviation} (get-in data [:std-scale :scaler id])]\\n                                  (/ (- (if log? (Math/log (xmap id)) (xmap id)) m) s)))]\\n    ((get-in data [:y :predict-fn])\\n     (.predict\\n       ^LinearModel (:ols data)\\n       (double-array\\n         (into [1.0] (for [c (:features-cols data)]          ;into [1.0] is the intercept. It's not obvious!!!\\n                       (condp = c\\n                         :Used_Duration (normalizer :Used_Duration (some #{:Used_Duration} (map :column (:transformations data))))\\n                         :Used_Rating_Score (normalizer :Used_Rating_Score false)\\n                         (keyword (str \\\"Country-\\\" (xmap :Country))) 1.0\\n                         (keyword (str \\\"Sector-\\\" (xmap :Sector))) 1.0\\n                         0.0))))))))\", :bg-class \"bg-light\"}] [:div nil]], \"112\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"148\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"208\" [:div [:p/code {:code \"(svr-predict-scalar svrmodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"127.29358711932846\\n\"}]]], \"137\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"140\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"136\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"166\" [:div [:p/code {:code \"(def qm (ds/->dataset \\\"resources/bonds.csv\\\" {:key-fn keyword}))\", :bg-class \"bg-light\"}] [:div nil]], \"121\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"194\" [:div [:p/code {:code \"(defn get-legacy-model-output\\n  [dataset]\\n  (-> dataset\\n      (legacy-model-definition)\\n      (prepare-data :ols)\\n      (ols-full-training)))\", :bg-class \"bg-light\"}] [:div nil]], \"168\" [:div nil [:div [:p/markdown \"For each model, we define which columns are categorical and need one-hot treatment, which need standard scaling, and which transformations will be applied to the data.\"]]], \"154\" [:div [:p/code {:code \"(ols-predict-scalar legacymodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"209\" [:div nil [:div [:p/markdown \"## END\"]]], \"110\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"174\" [:div [:p/code {:code \"(defn build-column\\n  [dataset line]\\n  (if (contains? line :assoc-fn)\\n    (assoc dataset (:column line) ((:assoc-fn line) dataset))\\n    (ds/column-map dataset (:column line) (:map-fn line) nil (:arg-cols line))))\", :bg-class \"bg-light\"}] [:div nil]], \"171\" [:div [:p/code {:code \"(defn svr-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn identity}\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}] [:div nil]], \"130\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"200\" [:div nil [:div [:p/markdown \"Let's add columns with all predictions to the original dataset.\"]]], \"183\" [:div [:p/code {:code \"(defn ols-full-training\\n  [data]\\n  (let [ols (OLS/fit (:ols-formula data) (:dataframe data))]\\n    (merge data\\n           {:ols ols\\n            :predictions ((get-in data [:y :predict-fn]) (vec (.predict ^LinearModel ols ^DataFrame (:dataframe data))))\\n            :rsq (.RSquared ^LinearModel ols)})))\", :bg-class \"bg-light\"}] [:div nil]], \"205\" [:div nil [:div [:p/markdown \"We can also try and predict the spread for any bond.\"]]], \"122\" [:div [:p/code {:code \"(defn build-column\\n  [dataset line]\\n  (if (contains? line :assoc-fn)\\n    (assoc dataset (:column line) ((:assoc-fn line) dataset))\\n    (ds/column-map dataset (:column line) (:map-fn line) nil (:arg-cols line))))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"149\" [:div [:p/code {:code \"(def res (assoc qm :legacy (:predictions legacymodel) :new (:predictions newmodel) :svr (:predictions svrmodel)))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"120\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"206\" [:div [:p/code {:code \"(ols-predict-scalar legacymodel {:Used_Duration 1.16 :Used_Rating_Score 6.0 :Country \\\"BH\\\" :Sector \\\"Ovy_naq_Gnf\\\"})\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"118.01535809799988\\n\"}]]], \"144\" [:div [:p/code {:code \"(defn get-svr-model-output\\n  [dataset]\\n  (-> dataset\\n      (svr-model-definition)\\n      (prepare-data :svr)\\n      (svr-full-training 0.05 1)))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"134\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"146\" [:div [:p/code {:code \"(def newmodel (get-new-model-output qm))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"177\" [:div [:p/code {:code \"(defn one-hot-reducer\\n  [source-dataset cols removals]\\n  (ds/remove-columns\\n    (reduce (fn [dataset col] (categorical/transform-one-hot dataset (categorical/fit-one-hot dataset col))) source-dataset cols)\\n    removals))\", :bg-class \"bg-light\"}] [:div nil]], \"125\" [:div [:p/code {:code \"(defn one-hot-reducer\\n  [source-dataset cols removals]\\n  (ds/remove-columns\\n    (reduce (fn [dataset col] (categorical/transform-one-hot dataset (categorical/fit-one-hot dataset col))) source-dataset cols)\\n    removals))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"165\" [:div nil [:div [:p/markdown \"The source data columns are `[:Bond :Used_Duration :Used_Rating_Score :Country :Sector]`. The target variable is called `:Used_ZTW` (z-spread to worst). The three models we run are:\\n* legacy: `log(Used_ZTW) = a.Used_Duration + b.Used_Rating_Score + categorical variables`\\n* new: `log(Used_ZTW) = a.log(Used_Duration) + b.Used_Rating_Score + categorical variables`\\n* svr: `Used_ZTW = SVR(Used_Duration, Used_Rating_Score, Country, Sector)`\"]]], \"153\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"142\" [:div [:p/code {:code \"(defn get-legacy-model-output\\n  [dataset]\\n  (-> dataset\\n      (legacy-model-definition)\\n      (prepare-data :ols)\\n      (ols-full-training)))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"127\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"109\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"124\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"138\" [:div [:p/code {:code \"(defn ols-predict-scalar [data xmap]\\n  (letfn [(normalizer [id log?] (let [{m :mean s :standard-deviation} (get-in data [:std-scale :scaler id])]\\n                                  (/ (- (if log? (Math/log (xmap id)) (xmap id)) m) s)))]\\n    ((get-in data [:y :predict-fn])\\n     (.predict\\n       ^LinearModel (:ols data)\\n       (double-array\\n         (into [1.0] (for [c (:features-cols data)]          ;into [1.0] is the intercept. It's not obvious!!!\\n                       (condp = c\\n                         :Used_Duration (normalizer :Used_Duration (some #{:Used_Duration} (map :column (:transformations data))))\\n                         :Used_Rating_Score (normalizer :Used_Rating_Score false)\\n                         (keyword (str \\\"Country-\\\" (xmap :Country))) 1.0\\n                         (keyword (str \\\"Sector-\\\" (xmap :Sector))) 1.0\\n                         0.0))))))))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"114\" [:div [:p/code {:code \"(def qm (ds/->dataset \\\"resources/bonds.csv\\\" {:key-fn keyword}))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"198\" [:div [:p/code {:code \"(def newmodel (get-new-model-output qm))\", :bg-class \"bg-light\"}] [:div nil]], \"133\" [:div [:p/code {:code \"(defn fit-RBF-SVR [x y sigma eps C]\\n  \\\"This is the SVR fit function, returning a smile.base.svm.KernelMachine which we can use to predict.\\n  x id a double double array, y is a double array, the rest are scalars.\\n  tol = 0.01 is irrelevant for the RBF (= Gaussian) kernel.\\n  sigma tunes the Kernel. The Python sklearn default is gamma = 'scale' where gamma = 1 / (2 * sigma^2)\\n  'scale' means gamma = 1 / (n_features * x.var()) hence sigma = sqrt(0.5 * n_features * x.var()) where x is flattened\\\"\\n  (.fit (SVR. (GaussianKernel. sigma) eps C 0.01) x y))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"147\" [:div [:p/code {:code \"(def svrmodel (get-svr-model-output qm))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"151\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"182\" [:div nil [:div [:p/markdown \"Training an OLS model is easy - we add the predictions and the R2.\"]]], \"189\" [:div nil [:div [:p/markdown \"The order of the data needs to match the order of the training data and *we need the intercept first, set at 1.0*. Note there's an ugly hack here in the ols predictor - normalizer is set to use log for the new model.\"]]], \"126\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"204\" [:div [:p/code {:code \"(ds/filter-column res :Bond \\\"Bond-42\\\")\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"resources/bonds.csv [1 9]:\\n\\n|   :Bond |     :Sector | :Country | :Used_Duration | :Used_Rating_Score | :Used_ZTW | :legacy |  :new |  :svr |\\n|---------|-------------|----------|----------------|--------------------|-----------|---------|-------|-------|\\n| Bond-42 | Ovy_naq_Gnf |       BH |           1.16 |                6.0 |      75.2 |   118.0 | 103.1 | 127.3 |\\n\\n\"}]]], \"143\" [:div [:p/code {:code \"(defn get-new-model-output\\n  [dataset]\\n  (-> dataset\\n      (new-model-definition)\\n      (prepare-data :ols)\\n      (ols-full-training)))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"178\" [:div nil [:div [:p/markdown \"We now are ready to prepare the data. There are several steps here:\\n* transform the data\\n* scale columns and save the scaling function so it can be reused later when predicting\\n* apply one-hot transformation to categorical variables\\n* get the data into a shape that's acceptable for smile.\"]]], \"170\" [:div [:p/code {:code \"(defn new-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn dfn/exp}\\n   :transformations [{:column :Used_ZTW          :assoc-fn #(dfn/log (% :Used_ZTW))}\\n                     {:column :Used_Duration     :assoc-fn #(dfn/log (% :Used_Duration))}]\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}] [:div nil]], \"131\" [:div [:p/code {:code \"(defn ols-full-training\\n  [data]\\n  (let [ols (OLS/fit (:ols-formula data) (:dataframe data))]\\n    (merge data\\n           {:ols ols\\n            :predictions ((get-in data [:y :predict-fn]) (vec (.predict ^LinearModel ols ^DataFrame (:dataframe data))))\\n            :rsq (.RSquared ^LinearModel ols)})))\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"161\" [:div nil [:div [:p/markdown \"We take an anonymized dataset of bonds across countries and sectors, with their durations, ratings and spreads. We are trying to infer the spread from the other four factors. We will use two OLS models and one support vector regression model. Note that rating and duration are continuous variables, whereas country and sector are categorical variables.\"]]], \"129\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"187\" [:div [:p/code {:code \"(defn svr-full-training [data eps C]\\n  ;todo find out why I'm still getting a Reflection warning: call to method predict on smile.base.svm.KernelMachine can't be resolved (no such method)\\n  (let [kernel-machine (fit-RBF-SVR (:features-array data) (:y-array data) (:sigma data) eps C)\\n        raw-predictions (.predict ^KernelMachine kernel-machine (:features-array data))\\n        rss (RSS/of (:y-array data) raw-predictions)]\\n    (merge data\\n           {:kernel-machine kernel-machine\\n            :predictions ((get-in data [:y :predict-fn]) (vec raw-predictions))\\n            :rsq (- 1 (/ rss (dfn/distance-squared (:y-array data) (repeat 0.))))})))\", :bg-class \"bg-light\"}] [:div nil]], \"164\" [:div nil [:div [:p/markdown \"## Model definitions\"]]], \"163\" [:div [:p/code {:code \"(comment\\n  ;; we'll be calling some Java methods\\n  ;; commenting this out, since it fails as a notespace note\\n  ;; (Can't set!: *warn-on-reflection* from non-binding thread)\\n  (set! *warn-on-reflection* true))\", :bg-class \"bg-light\"}] [:div [:p/code {:code \"nil\\n\"}]]], \"160\" [:div nil [:div [:p/markdown \"The purpose of this notebook is to show a basic machine learning pipeline with tech.ml.dataset.\"]]], \"150\" [:div [:p/code {:code \"(ds/head res)\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"117\" [:div [:p/code {:code \"(defn legacy-model-definition\\n  [dataset]\\n  {:dataset         dataset\\n   :id-name         :Bond\\n   :y               {:column :Used_ZTW :predict-fn dfn/exp}\\n   :transformations [{:column :Used_ZTW :assoc-fn #(dfn/log (% :Used_ZTW))}]\\n   :one-hot         {:columns [:Country :Sector] :removals [:Country-BH :Sector-Fvanapvny]}\\n   :std-scale       {:columns [:Used_Duration :Used_Rating_Score] :scaler nil}})\", :bg-class \"bg-light\"}] [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]], \"132\" [:div nil [:div [:p {:style {:font-style \"italic\", :font-family \"\\\"Lucida Console\\\", Courier, monospace\"}} [:small \"(not evaluated yet)\"]]]]}}");
     document.getElementById("loading").remove();
    </script>
</html>
